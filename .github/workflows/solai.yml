name: solai-phase3-hello-world
on: [push]

defaults:
  run:
    shell: bash

env:
  DEBUG: "false"  # default debug flag for SWE-agent steps
  # Cache key prefix for pip dependencies
  PIP_CACHE_PREFIX: pip-lint-test
  SLITHER_TAG: "latest-slim"  # Centralize Slither version

jobs:
  # quick syntax check of GH workflow
  lint-workflow:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Check workflow files (Docker)
        uses: docker://rhysd/actionlint:latest

  lint-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python for linting/testing
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      # → Cache pip install for linters/testers
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          # P1: Unify pip cache key - use requirements.txt hash as proxy now
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}-py3.12
          restore-keys: |
            ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}-
            ${{ runner.os }}-pip-

      - name: Install build + lock tools # Updated name and command
        run: |
          python -m pip install --quiet "pip<25" "pip-tools>=7.4,<7.5"

      - name: Verify requirements.txt is in sync
        run: ci/verify_lock.sh

      - name: Run actionlint (GitHub Workflow lint)
        uses: reviewdog/action-actionlint@v1
        with:
          reporter: github-pr-check

      - name: Lint Python code with Ruff
        uses: astral-sh/ruff-action@v3
        with:
          args: "check --output-format=github"

      - name: Lint shell scripts with ShellCheck
        uses: ludeeus/action-shellcheck@2.0.0
        with:
          scandir: ci
        env:
          SHELLCHECK_OPTS: -e SC2148

      - name: Build wheel for lint job
        run: python -m build --wheel

      - name: Cache Built Wheel # P1: Cache the dist directory
        uses: actions/cache@v4
        with:
          path: dist
          key: ${{ github.sha }}-wheel

      - name: Install wheel and test dependencies # Updated name and command
        run: |
          set -e
          # Install the built wheel
          wheel_file=$(find dist -maxdepth 1 -name 'solai-*.whl' -print -quit)
          if [[ -z "$wheel_file" ]]; then
            echo "::error::Wheel file not found in dist/ directory."
            ls -l dist/ # List contents for debugging
            exit 1
          fi
          echo "Installing wheel: ${wheel_file}"
          python -m pip install --quiet "${wheel_file}"

          # Install dependencies from lock file, respecting hashes
          echo "Installing dependencies from requirements.txt"
          # Separate Git and PyPI dependencies
          tmp_git_reqs=$(mktemp)
          tmp_pypi_reqs=$(mktemp)
          filtered_pypi=$(mktemp)
          grep    '@ git+' requirements.txt > "$tmp_git_reqs"  || true # Allow empty file
          grep -v '@ git+' requirements.txt > "$tmp_pypi_reqs" || true # Allow empty file

          # Install Git dependencies first (no hash check possible)
          if [[ -s "$tmp_git_reqs" ]]; then
            echo "Installing Git dependencies..."
            python -m pip install --quiet --no-cache-dir -r "$tmp_git_reqs"
          else
            echo "No Git dependencies found."
          fi

          # Install PyPI dependencies with hash checking
          if [[ -s "$tmp_pypi_reqs" ]]; then
            echo "Installing PyPI dependencies with hash checking..."
            # Filter out dev/unsafe tools that break --require-hashes
            grep -vE '^(pip|setuptools|pip-tools)==' "$tmp_pypi_reqs" > "$filtered_pypi"
            python -m pip install --quiet --no-cache-dir -r "$filtered_pypi" --require-hashes
          else
            echo "No PyPI dependencies found."
          fi

          # Clean up temp files
          rm "$tmp_git_reqs" "$tmp_pypi_reqs" "$filtered_pypi"

      - name: Check pip dependencies (lint job)
        run: python -m pip check

      - name: Run tests & Generate Coverage XML # P2: Generate coverage.xml
        run: |
          set -e
          echo "--- Running pytest ---"
          # Generate XML report for coverage
          pytest -q --cov=solai --cov-report=term-missing --cov-report=xml:coverage.xml --cov-fail-under=0
          {
            echo "### Pytest passed"
            echo "### Coverage Report"
            coverage report
          } >> "$GITHUB_STEP_SUMMARY"

      # P2: Upload coverage report
      - name: Upload Coverage Report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage.xml
          if-no-files-found: warn # Don't fail build if file missing

  phase3_hello_world:
    needs: [lint-workflow, lint-and-test]
    runs-on: ubuntu-latest
    timeout-minutes: 25
    env:
      # Define FOUNDRY_DIR at job level for use in cache and install steps
      FOUNDRY_DIR: /home/runner/.config/.foundry

    steps:
      # → Cache Python deps
      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          # P1: Use requirements.txt for consistency with lint job
          key: ${{ runner.os }}-pip-phase3-${{ hashFiles('requirements.txt') }}-py3.12
          restore-keys: |
            ${{ runner.os }}-pip-phase3-${{ hashFiles('requirements.txt') }}-
            ${{ runner.os }}-pip-phase3-

      # 1) Grab your code
      - uses: actions/checkout@v4

      # 2) Ensure Python 3.12
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      # Export runner's interpreter path for root
      - name: Export PYBIN_DIR
        run: echo "PYBIN_DIR=$(python -c 'import sys, pathlib; print(pathlib.Path(sys.executable).parent)')" >> "$GITHUB_ENV"

      # 4) Install your wheel + AI backends via pip
      - name: Restore Cached Wheel # P1: Restore wheel from lint job cache
        id: cache-wheel-restore
        uses: actions/cache@v4
        with:
          path: dist
          key: ${{ github.sha }}-wheel # Must match the save key

      - name: Install solai wheel (from cache or build) # P1: Use cached wheel
        run: |
          set -e # Exit immediately if a command exits with a non-zero status.
          # Use find to safely handle glob patterns (avoids issues with spaces and special characters)
          wheel_files=()
          while IFS= read -r -d '' file; do
            wheel_files+=("$file")
          done < <(find dist -maxdepth 1 -name 'solai-*.whl' -print0)

          # Check if cache hit AND exactly one wheel file exists
          if [[ "${{ steps.cache-wheel-restore.outputs.cache-hit }}" == 'true' && -e "${wheel_files[0]}" && ${#wheel_files[@]} -eq 1 ]]; then
            wheel_file="${wheel_files[0]}" # Assign the exact filename
            echo "Installing wheel from cache: ${wheel_file}"
            python -m pip install --quiet "${wheel_file}"
          else
            # Provide clearer feedback based on cache status
            if [[ "${{ steps.cache-wheel-restore.outputs.cache-hit }}" == 'true' ]]; then
               # Cache hit but file missing/wrong count
               echo "Warning: Wheel cache hit, but wheel file missing or unexpected count (${#wheel_files[@]}). Rebuilding."
            else
               echo "Wheel cache miss. Building and installing wheel."
            fi

            # Build the wheel
            echo "Installing build tool..."
            python -m pip install --quiet build
            echo "Building wheel..."
            python -m build --wheel

            # Re-check for the wheel file after build
            wheel_files_after_build=()
            while IFS= read -r -d '' file; do
              wheel_files_after_build+=("$file")
            done < <(find dist -maxdepth 1 -name 'solai-*.whl' -print0)
            
            if [[ -e "${wheel_files_after_build[0]}" && ${#wheel_files_after_build[@]} -eq 1 ]]; then
              wheel_file="${wheel_files_after_build[0]}"
              echo "Installing newly built wheel: ${wheel_file}"
              python -m pip install --quiet "${wheel_file}"
            else
              echo "Error: Could not find exactly one wheel file in dist/ after build. Found ${#wheel_files_after_build[@]} files."
              ls -l dist/
              exit 1
            fi
          fi

      # Centralize PyYAML install for syntax checking later
      - name: Install PyYAML
        run: python -m pip install --quiet pyyaml

      # -------------------------------------------------------------
      # 4b) Determine latest Foundry version (does NOT need Foundry)
      # -------------------------------------------------------------
      - name: Lock Foundry version to v1.6.5
        id: foundry_version
        run: echo "version=v1.6.5" >> "$GITHUB_OUTPUT"

      # -------------------------------------------------------------
      # 4c) Restore Foundry from cache (if we already built it once)
      # -------------------------------------------------------------
      - name: Cache Foundry directory
        id: cache-foundry
        uses: actions/cache@v4
        with:
          path: ${{ env.FOUNDRY_DIR }}
          key: ${{ runner.os }}-foundry-${{ steps.foundry_version.outputs.version }}

      - name: Restore Foundry from cache
        if: steps.cache-foundry.outputs.cache-hit == 'true'
        run: |
          echo "${FOUNDRY_DIR}/bin" >> "$GITHUB_PATH"
          export PATH="${FOUNDRY_DIR}/bin:$PATH"
          forge --version

      # -------------------------------------------------------------
      # 4d) Install Foundry (ONLY if cache missed)
      # -------------------------------------------------------------
      - name: Install Foundry
        if: steps.cache-foundry.outputs.cache-hit != 'true'
        run: |
          # 1) Create Foundry directory
          mkdir -p "${FOUNDRY_DIR}/bin"
          # 2) Download foundryup directly into the standard dir
          curl -L https://raw.githubusercontent.com/foundry-rs/foundry/master/foundryup/foundryup \
               -o "${FOUNDRY_DIR}/bin/foundryup"
          # 3) Make executable
          chmod +x "${FOUNDRY_DIR}/bin/foundryup"
          # 4) Add to temp PATH
          export PATH="${FOUNDRY_DIR}/bin:$PATH"
          # 5) Install full suite
          foundryup || echo "foundryup command failed with exit code $?"
          # 6) Verify
          ls -la "${FOUNDRY_DIR}/bin/forge"
          # 7) Persist correct path
          echo "${FOUNDRY_DIR}/bin" >> "$GITHUB_PATH"
          # 8) Verify again
          export PATH="${FOUNDRY_DIR}/bin:$PATH"
          which forge
          forge --version

      # Debug: Post Docker PATH
      - name: Debug - Post Docker PATH
        if: ${{ env.DEBUG == 'true' }}
        run: |
          echo "PATH after Docker setup: $PATH"
          cat "$GITHUB_PATH"
          # skip redundant Foundry install if cache hit
          if [[ "${{ steps.cache-foundry.outputs.cache-hit }}" == 'true' ]]; then
            echo "Foundry cache hit – skipping binary path export"
          else
            which forge || echo "forge not found in PATH"
          fi

      # 4e) Install SWE-Agent & dependencies via requirements file # Updated name and command
      - name: Install SWE-Agent & dependencies via lock file
        run: |
          set -xeuo pipefail
          # P1: Install using lock file for reproducibility & security
          echo "Installing dependencies from requirements.txt"

          # Separate Git and PyPI dependencies
          tmp_git_reqs=$(mktemp)
          tmp_pypi_reqs=$(mktemp)
          grep    '@ git+' requirements.txt > "$tmp_git_reqs"  || true # Allow empty file
          grep -v '@ git+' requirements.txt > "$tmp_pypi_reqs" || true # Allow empty file

          # Install Git dependencies first (no hash check possible)
          if [[ -s "$tmp_git_reqs" ]]; then
            echo "Installing Git dependencies..."
            python -m pip install --quiet --no-cache-dir -r "$tmp_git_reqs"
          else
            echo "No Git dependencies found."
          fi

          # Install PyPI dependencies with hash checking, excluding dev/unsafe tools
          if [[ -s "$tmp_pypi_reqs" ]]; then
            echo "Installing PyPI dependencies with hash checking..."
            # Filter out dev/unsafe tools that break --require-hashes
            grep -vE '^(pip|setuptools|pip-tools)==' "$tmp_pypi_reqs" \
              | python -m pip install --quiet --no-cache-dir -r /dev/stdin --require-hashes
          else
            echo "No PyPI dependencies found."
          fi

          # Clean up temp files
          rm "$tmp_git_reqs" "$tmp_pypi_reqs"

          echo "+++ Creating runtime stubs ..."
          python scripts/setup_stub_pkgs.py
          echo "+++ Verifying stubs ..."
          python scripts/verify_sweagent_setup.py # Run verification script

          # Add verification of site-packages structure (refined log)
          echo "+++ Verifying site-packages structure (relevant directories)..."
          SITE_PKG_PATH=$(python -c 'import site; print(site.getsitepackages()[0])')
          echo "Relevant directories found in: $SITE_PKG_PATH"
          # Use find for targeted listing
          find "$SITE_PKG_PATH" -maxdepth 1 -type d \( -name config -o -name tools -o -name trajectories -o -name enterprise \) -print || echo "Warning: find command failed or no relevant directories found."
          echo "--- Site-packages structure verification complete."

          # Original smoke test (optional, keep for belt-and-suspenders)
          echo "+++ Running original import smoke-test..."
          python -c 'import sweagent; print("import ok:", sweagent.__version__)'
          echo "--- Original import smoke-test finished."

      - name: Check pip dependencies (phase3 job)
        run: python -m pip check

      # 7) Run Phase 3 Hello-World Test
      - name: Phase 3 - SWE-Agent Run
        id: swe_agent_run_step
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          PYBIN_DIR: ${{ env.PYBIN_DIR }}
        # only preserve the two env vars
        shell: sudo --preserve-env=OPENAI_API_KEY,PYBIN_DIR bash -e {0}
        run: ci/phase3.sh

      # 8) Upload Phase 3 Evidence Bundle
      - name: Upload Phase 3 Evidence
        uses: actions/upload-artifact@v4
        with:
          name: phase3-evidence
          path: /tmp/${{ steps.swe_agent_run_step.outputs.bundle_name }}
          if-no-files-found: error 